{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1675282d-9508-4525-b0b7-a1867a448dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess as mp\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import dbfread \n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pyproj\n",
    "from simpledbf import Dbf5\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84896915-4b0f-4f57-afd1-4cabec55b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 339 data, for no depth info\n",
      "- 2520 data, for no time info\n",
      "- 0 data, for no coordinate info\n",
      "3412 data left in crotia\n"
     ]
    }
   ],
   "source": [
    "# crotia, harmonized dataset from MultiOne\n",
    "crotia = pd.read_excel('/mnt/primus/xuemeng_tmp_harbour/soc_eu/crotia/hr_topsoil_db.xlsx')\n",
    "\n",
    "# filter/organize based on depth\n",
    "na = crotia[crotia['source_db']=='martinovic_1997']['dbr'].isna().sum()\n",
    "print(f'- {na} data, for no depth info')\n",
    "crotia = crotia[~((crotia['source_db'] == 'martinovic_1997') & (crotia['dbr'].isna()))]  # without any depth information, leave out\n",
    "crotia['hzn_top'] = 0\n",
    "crotia['hzn_btm'] = 30\n",
    "crotia.loc[crotia['source_db'] == 'martinovic_1997', 'hzn_top'] = crotia.loc[crotia['source_db'] == 'martinovic_1997', 'dbr'] - 5\n",
    "crotia.loc[crotia['source_db'] == 'martinovic_1997', 'hzn_btm'] = crotia.loc[crotia['source_db'] == 'martinovic_1997', 'dbr'] + 5\n",
    "crotia.loc[crotia['source_db'] == 'azo_2013', 'hzn_btm'] = 25\n",
    "\n",
    "\n",
    "column_names = ['ph_h2o','ph_ca','oc','gps_lat','gps_long','time','hzn_top','hzn_btm','ref','ph_kcl']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['oc'] = crotia['oc']*10\n",
    "temp['ph_kcl'] = crotia['ph_kcl']\n",
    "temp['ph_h2o'] = crotia['ph_h2o']\n",
    "temp['ph_ca'] = np.nan\n",
    "temp['ref'] = crotia['source_db']+'_MultiOne'\n",
    "temp['gps_lat'] = crotia['latitude_decimal_degrees']\n",
    "temp['gps_long'] = crotia['longitude_decimal_degrees']\n",
    "temp['country'] = 'crotia'\n",
    "temp['time'] = crotia['site_obsdate']\n",
    "temp['hzn_top'] = crotia['hzn_top']\n",
    "temp['hzn_btm'] = crotia['hzn_btm']\n",
    "# df = pd.concat([df,temp])\n",
    "\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'- {na} data, for no time info')\n",
    "temp = temp.dropna(subset=['time'])\n",
    "\n",
    "na = len(temp[temp['gps_lat'].isna() | temp['gps_long'].isna()])\n",
    "print(f'- {na} data, for no coordinate info')\n",
    "temp = temp.dropna(subset=['gps_lat','gps_long'])\n",
    "\n",
    "print(f'{len(temp)} data left in crotia')\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/training_point_v2_crotia.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d9baba-b03e-4e2c-b742-d0f211e61f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 data, for no time info\n",
      "- 0 data, for no coordinate info\n",
      "- 0 data, for no depth info\n",
      "17189 data left in germany\n"
     ]
    }
   ],
   "source": [
    "# germany\n",
    "germany = pd.read_excel(r'/mnt/diskstation/data/soil_points/Germany/LABORATORY_DATA.xlsx', engine='openpyxl')\n",
    "germany_site = pd.read_excel(r'/mnt/diskstation/data/Soil_points/Germany/SITE.xlsx', engine='openpyxl')\n",
    "germany = germany.merge(germany_site, on=\"PointID\", how=\"inner\")\n",
    "utm_projection = pyproj.CRS.from_string(f'+proj=utm +zone={32} +ellps=WGS84')\n",
    "gps_projection = pyproj.CRS.from_epsg(4326)\n",
    "# Create transformer objects for the coordinate conversion\n",
    "transformer = pyproj.Transformer.from_crs(utm_projection, gps_projection)\n",
    "# Convert UTM coordinates to GPS latitude and longitude\n",
    "germany['lat'], germany['lon'] = transformer.transform(germany['xcoord'], germany['ycoord'])\n",
    "column_names = ['ph_h2o','ph_ca','oc','gps_lat','gps_long','time','hzn_top','hzn_btm','ref','ph_kcl']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['oc'] = germany['TOC']\n",
    "temp['ph_kcl'] = np.nan\n",
    "temp['ph_h2o'] = germany['pH_H2O']\n",
    "temp['ph_ca'] = germany['pH_CaCl2']\n",
    "temp['time'] = germany['Sampling_year']\n",
    "temp['hzn_top'] = germany['Layer upper limit']\n",
    "temp['hzn_btm'] = germany['Layer lower limit']\n",
    "temp['ref'] = 'https://literatur.thuenen.de/digbib_extern/dn062722.pdf'\n",
    "temp['gps_lat'] = germany['lat']\n",
    "temp['gps_long'] = germany['lon']\n",
    "temp['country'] = 'germany'\n",
    "\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'- {na} data, for no time info')\n",
    "temp = temp.dropna(subset=['time'])\n",
    "\n",
    "na = len(temp[temp['gps_lat'].isna() | temp['gps_long'].isna()])\n",
    "print(f'- {na} data, for no coordinate info')\n",
    "temp = temp.dropna(subset=['gps_lat','gps_long'])\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'- {na} data, for no depth info')\n",
    "temp = temp.dropna(subset=['hzn_top','hzn_btm'])\n",
    "\n",
    "print(f'{len(temp)} data left in germany')\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/training_point_v2_germany.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a425485-9f30-4c18-8254-0286d403f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 3536 data, for no time info\n",
      "- 5 data, for invalid time info\n",
      "- 224 data, for no valid depth info\n",
      "- 0 data, for no depth info\n",
      "- 28 data, for no coordinate info\n",
      "- 514 data, for duplicate time, coordinate, and depth info\n",
      "36309 data left in belgium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151658/3479290969.py:30: RuntimeWarning: All-NaN axis encountered\n",
      "  belgium['hzn_top'] = np.nanmin(belgium[['Diepte_grens_boven1', 'Diepte_grens_boven2']], axis=1)\n",
      "/tmp/ipykernel_151658/3479290969.py:31: RuntimeWarning: All-NaN axis encountered\n",
      "  belgium['hzn_btm'] = np.nanmax(belgium[['Diepte_grens_onder1', 'Diepte_grens_onder2']], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# +belgium\n",
    "# read in 2 sites\n",
    "belgium_p = pd.read_csv('/mnt/diskstation/data/soil_points/Belgium/Vlaanderen/Aardewerk-Vlaanderen-2010_Profiel.csv')\n",
    "belgium_h = pd.read_csv('/mnt/diskstation/data/soil_points/Belgium/Vlaanderen/Aardewerk-Vlaanderen-2010_Horizont.csv',low_memory=False,encoding = \"ISO-8859-1\")\n",
    "# merge 2 sites\n",
    "belgium_p = belgium_p.rename(columns={'ID': 'Profiel_ID'}) \n",
    "belgium = belgium_h.merge(belgium_p, on=\"Profiel_ID\", how=\"inner\")\n",
    "# Define the coordinate systems\n",
    "lambert72 = pyproj.CRS.from_epsg(31370)  # Lambert72 CRS\n",
    "wgs84 = pyproj.CRS.from_epsg(4326)  # WGS84 CRS (GPS)\n",
    "transformer = pyproj.Transformer.from_crs(lambert72, wgs84)\n",
    "belgium['lat'], belgium['lon'] = transformer.transform(belgium['Coordinaat_Lambert72_X'], belgium['Coordinaat_Lambert72_Y'])\n",
    "# belgium['Y'], belgium['X'] = transformer.transform(belgium['Coordinaat_Bonne_E'], belgium['Coordinaat_Bonne_N'])\n",
    "\n",
    "# convert humus to oc\n",
    "belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==0, 'Humus'] = belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==0, 'Humus'] / 1.724\n",
    "belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==1, 'Humus'] = belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==1, 'Humus'] / 2\n",
    "\n",
    "# extract time info \n",
    "na = belgium['Profilering_Datum'].isna().sum()\n",
    "print(f'- {na} data, for no time info')\n",
    "belgium = belgium.dropna(subset=['Profilering_Datum'])\n",
    "belgium['Profilering_Datum'] = belgium['Profilering_Datum'].str.split(' ').str[0]\n",
    "belgium['Profilering_Datum'] = belgium['Profilering_Datum'].str.split('-').str[-1].astype(int)\n",
    "na = len(belgium.loc[belgium['Profilering_Datum']==2094])\n",
    "print(f'- {na} data, for invalid time info')\n",
    "belgium = belgium[belgium['Profilering_Datum'] != 2094]\n",
    "\n",
    "# extract depth info\n",
    "belgium['hzn_top'] = np.nanmin(belgium[['Diepte_grens_boven1', 'Diepte_grens_boven2']], axis=1)\n",
    "belgium['hzn_btm'] = np.nanmax(belgium[['Diepte_grens_onder1', 'Diepte_grens_onder2']], axis=1)\n",
    "\n",
    "na = len(belgium.loc[belgium['hzn_top']>=belgium['hzn_btm']])\n",
    "print(f'- {na} data, for no valid depth info')\n",
    "belgium = belgium.loc[belgium['hzn_top'] < belgium['hzn_btm']]\n",
    "\n",
    "na = len(belgium[belgium['hzn_btm'].isna() | belgium['hzn_top'].isna()])\n",
    "print(f'- {na} data, for no depth info')\n",
    "belgium = belgium.dropna(subset=['hzn_top','hzn_btm'], how='any')\n",
    "\n",
    "# merge belgium data into lucas\n",
    "column_names = ['ph_h2o','ph_ca','oc','gps_lat','gps_long','time','hzn_top','hzn_btm','ref','ph_kcl']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['oc'] = belgium['Humus']*10\n",
    "temp['ph_kcl'] = belgium['pH_KCl']\n",
    "temp['ph_h2o'] = belgium['pH_H2O']\n",
    "temp['ph_ca'] = np.nan\n",
    "temp['time'] = belgium['Profilering_Datum']\n",
    "temp['hzn_top'] = belgium['Diepte_grens_boven1']\n",
    "temp['hzn_btm'] = belgium['Diepte_grens_onder1']\n",
    "temp.loc[temp['hzn_top'].isna(),'hzn_top'] = belgium.loc[temp['hzn_top'].isna(),'Diepte_grens_boven2']\n",
    "temp.loc[temp['hzn_btm'].isna(),'hzn_btm'] = belgium.loc[temp['hzn_btm'].isna(),'Diepte_grens_onder2']\n",
    "temp['hzn_top'] = np.nanmax(belgium[['Diepte_grens_boven1', 'Diepte_grens_boven2']], axis=1)\n",
    "temp['hzn_btm'] = np.nanmax(belgium[['Diepte_grens_onder1', 'Diepte_grens_onder2']], axis=1)     \n",
    "temp['gps_lat'] = belgium['lat']\n",
    "temp['gps_long'] = belgium['lon']\n",
    "\n",
    "# filter based on coordinates\n",
    "na = len(temp[temp['gps_lat'].isna() | temp['gps_long'].isna()])\n",
    "print(f'- {na} data, for no coordinate info')\n",
    "temp = temp.dropna(subset=['gps_lat','gps_long'])\n",
    "\n",
    "# merge duplicates\n",
    "dupm = temp.groupby(['gps_lat', 'gps_long', 'time','hzn_top','hzn_btm'])[['oc', 'ph_h2o','ph_kcl','ph_ca']].mean().reset_index()\n",
    "dupm['ref'] = 'https://www.dov.vlaanderen.be/geonetwork/srv/api/records/78e15dd4-8070-4220-afac-258ea040fb30'\n",
    "dupm['country'] = 'belgium'\n",
    "print(f'- {len(temp)-len(dupm)} data, for duplicate time, coordinate, and depth info')\n",
    "\n",
    "print(f'{len(dupm)} data left in belgium')\n",
    "dupm.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/training_point_v2_belgium.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884efdd0-e166-460b-a6ef-cdb9910b37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 data, for no time info\n",
      "- 0 data, for no coordinate info\n",
      "- 86 data, for no depth info\n",
      "3005 data left in scotland\n"
     ]
    }
   ],
   "source": [
    "# scotland\n",
    "scotland = pd.read_excel('/mnt/diskstation/data/soil_points/Scotland/NSIS_1_10km_grid_gh.xlsx', sheet_name='NSIS1_10km')\n",
    "osgb36 = pyproj.CRS.from_string(\"+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894 +units=m +no_defs\")\n",
    "wgs84 = pyproj.CRS.from_epsg(4326)\n",
    "transformer = pyproj.Transformer.from_crs(osgb36, wgs84)\n",
    "scotland['lat'], scotland['lon'] = transformer.transform(scotland['EASTING'], scotland['NORTHING'])\n",
    "column_names = ['ph_h2o','ph_ca','oc','gps_lat','gps_long','time','hzn_top','hzn_btm','ref','ph_kcl']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['oc'] = scotland['DP1971_ORGANIC_MATTER']/1.72\n",
    "temp['ph_kcl'] = np.nan\n",
    "temp['ph_h2o'] = scotland['DP1971_PH_H2O']\n",
    "temp['ph_ca'] = scotland['DP1971_PH_CACL2']\n",
    "temp['ref'] = 'https://www.hutton.ac.uk/about/facilities/national-soils-archive/resampling-soils-inventory'\n",
    "temp['gps_lat'] = scotland['lat']\n",
    "temp['gps_long'] = scotland['lon']\n",
    "temp['country'] = 'scotland'\n",
    "temp['time'] = scotland['PROFILE_DATE'].astype(str).str[-4:]\n",
    "temp['hzn_top'] = scotland['HORZ_TOP']\n",
    "temp['hzn_btm'] = scotland['HORZ_BOTTOM']\n",
    "\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'- {na} data, for no time info')\n",
    "temp = temp.dropna(subset=['time'])\n",
    "\n",
    "na = len(temp[temp['gps_lat'].isna() | temp['gps_long'].isna()])\n",
    "print(f'- {na} data, for no coordinate info')\n",
    "temp = temp.dropna(subset=['gps_lat','gps_long'])\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'- {na} data, for no depth info')\n",
    "temp = temp.dropna(subset=['hzn_top','hzn_btm'])\n",
    "\n",
    "print(f'{len(temp)} data left in scotland')\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/training_point_v2_scotland.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a044e-ee44-4212-8e2e-91c641df49d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
