{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1675282d-9508-4525-b0b7-a1867a448dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess as mp\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/opt/conda/share/proj')\n",
    "import pandas as pd\n",
    "import dbfread \n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pyproj\n",
    "from simpledbf import Dbf5\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb38a29-8b9b-4959-acfe-7e122254c1af",
   "metadata": {},
   "source": [
    "#### clean depth, time and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861efafe-fbee-40cc-818b-12c167dd2666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6271 data in total\n",
      "2556 data with no time info\n",
      "339 data with no depth info\n",
      "0 data with no coordinate info\n"
     ]
    }
   ],
   "source": [
    "# crotia, harmonized dataset from MultiOne\n",
    "crotia = pd.read_excel('/mnt/primus/xuemeng_tmp_harbour/soc_eu/crotia/hr_topsoil_db.xlsx')\n",
    "\n",
    "# organize the depth\n",
    "crotia.loc[crotia['dbr'].isna(), 'hzn_top'] = np.nan\n",
    "crotia.loc[crotia['dbr'].isna(), 'hzn_btm'] = np.nan\n",
    "crotia.loc[~crotia['dbr'].isna(), 'hzn_top'] = crotia.loc[~crotia['dbr'].isna(), 'dbr'] - 10\n",
    "crotia.loc[~crotia['dbr'].isna(), 'hzn_btm'] = crotia.loc[~crotia['dbr'].isna(), 'dbr'] + 10\n",
    "crotia.loc[crotia['source_db'].isin(['agricultural_2013','azo_2016']), 'hzn_btm'] = 30\n",
    "crotia.loc[crotia['source_db'].isin(['agricultural_2013','azo_2016']), 'hzn_top'] = 0\n",
    "crotia.loc[crotia['source_db'] == 'azo_2013', 'hzn_top'] = 0\n",
    "crotia.loc[crotia['source_db'] == 'azo_2013', 'hzn_btm'] = 25\n",
    "\n",
    "column_names = ['lat','lon','time','hzn_top','hzn_btm','ref']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['lat'] = crotia['latitude_decimal_degrees']\n",
    "temp['lon'] = crotia['longitude_decimal_degrees']\n",
    "temp['nuts0'] = 'HR'\n",
    "temp['time'] = crotia['site_obsdate']\n",
    "temp['hzn_top'] = crotia['hzn_top']\n",
    "temp['hzn_btm'] = crotia['hzn_btm']\n",
    "temp['ref'] = 'croatia.multione-'+ crotia['source_db']\n",
    "temp['oc'] = crotia['oc']*10 # % -> g/kg\n",
    "temp['ph_cacl2'] = (crotia['ph_kcl']+0.09)*0.987+0.321 # convert from ph_kcl to ph_cacl2\n",
    "temp['ph_h2o'] = crotia['ph_h2o']\n",
    "# temp['ph_cacl2'] = np.nan\n",
    "temp['bulk_density'] = crotia['db_od']\n",
    "temp['clay'] = crotia['clay_tot_psa']\n",
    "temp['silt'] = crotia['silt_tot_psa']\n",
    "temp['sand'] = crotia['sand_tot_psa']\n",
    "temp['caco3'] = crotia['caco3']*10 # % -> g/kg\n",
    "temp['N'] = crotia['n_tot_ncs']*10 # % -> g/kg\n",
    "temp['K'] = crotia['k_mehlich3']*0.965 + 7.13 # mehlich convert to AAE\n",
    "# temp['P'] = crotia['p_mehlich3'] # mehlich3 - olsen method  not convertable\n",
    "\n",
    "# basic info\n",
    "print(f'{len(temp)} data in total')\n",
    "\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'{na} data with no time info')\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'{na} data with no depth info')\n",
    "\n",
    "na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "print(f'{na} data with no coordinate info')\n",
    "\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/croatia_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d9baba-b03e-4e2c-b742-d0f211e61f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17189 data in total\n",
      "0 data with no time info\n",
      "0 data with no depth info\n",
      "0 data with no coordinate info\n"
     ]
    }
   ],
   "source": [
    "# germany\n",
    "germany = pd.read_excel(r'/mnt/diskstation/data/soil_points/Germany/LABORATORY_DATA.xlsx', engine='openpyxl')\n",
    "germany_site = pd.read_excel(r'/mnt/diskstation/data/Soil_points/Germany/SITE.xlsx', engine='openpyxl')\n",
    "germany = germany.merge(germany_site, on=\"PointID\", how=\"inner\")\n",
    "utm_projection = pyproj.CRS.from_string(f'+proj=utm +zone={32} +ellps=WGS84')\n",
    "gps_projection = pyproj.CRS.from_epsg(4326)\n",
    "# Create transformer objects for the coordinate conversion\n",
    "transformer = pyproj.Transformer.from_crs(utm_projection, gps_projection)\n",
    "# Convert UTM coordinates to GPS latitude and longitude\n",
    "germany['lat'], germany['lon'] = transformer.transform(germany['xcoord'], germany['ycoord'])\n",
    "\n",
    "column_names = ['lat','lon','time','hzn_top','hzn_btm','ref']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['time'] = germany['Sampling_year']\n",
    "temp['hzn_top'] = germany['Layer upper limit']\n",
    "temp['hzn_btm'] = germany['Layer lower limit']\n",
    "temp['ref'] = 'germany.thuenen-'+germany['County_x']\n",
    "temp['lat'] = germany['lat']\n",
    "temp['lon'] = germany['lon']\n",
    "temp['nuts0'] = 'DE'\n",
    "temp['oc'] = germany['TOC']\n",
    "temp['N'] = germany['TN']\n",
    "temp['ph_kcl'] = np.nan\n",
    "temp['ph_h2o'] = germany['pH_H2O']\n",
    "temp['ph_cacl2'] = germany['pH_CaCl2']\n",
    "temp['bulk_density'] = germany['BD_bulk']\n",
    "temp['clay'] = germany['Clay']\n",
    "temp['silt'] = germany['Silt']\n",
    "temp['sand'] = germany['Sand']\n",
    "temp['caco3'] = np.nan\n",
    "temp['K'] = np.nan\n",
    "temp['P'] = np.nan\n",
    "\n",
    "# basic info\n",
    "print(f'{len(temp)} data in total')\n",
    "\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'{na} data with no time info')\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'{na} data with no depth info')\n",
    "\n",
    "na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "print(f'{na} data with no coordinate info')\n",
    "\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/germany_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a425485-9f30-4c18-8254-0286d403f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3541 data with no time info\n",
      "3172 data with no depth info\n",
      "740 data with no coordinate info\n",
      "42529 in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1792382/3425476731.py:25: RuntimeWarning: All-NaN axis encountered\n",
      "  belgium['hzn_top'] = np.nanmin(belgium[['Diepte_grens_boven1', 'Diepte_grens_boven2']], axis=1)\n",
      "/tmp/ipykernel_1792382/3425476731.py:26: RuntimeWarning: All-NaN axis encountered\n",
      "  belgium['hzn_btm'] = np.nanmax(belgium[['Diepte_grens_onder1', 'Diepte_grens_onder2']], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# +belgium\n",
    "# read in 2 sites\n",
    "belgium_p = pd.read_csv('/mnt/diskstation/data/soil_points/Belgium/Vlaanderen/Aardewerk-Vlaanderen-2010_Profiel.csv')\n",
    "belgium_h = pd.read_csv('/mnt/diskstation/data/soil_points/Belgium/Vlaanderen/Aardewerk-Vlaanderen-2010_Horizont.csv',low_memory=False,encoding = \"ISO-8859-1\")\n",
    "# merge 2 sites\n",
    "belgium_p = belgium_p.rename(columns={'ID': 'Profiel_ID'}) \n",
    "belgium = belgium_h.merge(belgium_p, on=\"Profiel_ID\", how=\"inner\")\n",
    "# Define the coordinate systems\n",
    "lambert72 = pyproj.CRS.from_epsg(31370)  # Lambert72 CRS\n",
    "wgs84 = pyproj.CRS.from_epsg(4326)  # WGS84 CRS (GPS)\n",
    "transformer = pyproj.Transformer.from_crs(lambert72, wgs84)\n",
    "belgium['lat'], belgium['lon'] = transformer.transform(belgium['Coordinaat_Lambert72_X'], belgium['Coordinaat_Lambert72_Y'])\n",
    "# belgium['Y'], belgium['X'] = transformer.transform(belgium['Coordinaat_Bonne_E'], belgium['Coordinaat_Bonne_N'])\n",
    "\n",
    "# convert humus to oc\n",
    "belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==0, 'Humus'] = belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==0, 'Humus']*4/3/1.724\n",
    "belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==1, 'Humus'] = belgium.loc[belgium['Humus_koolstof_nieuwe_formule']==1, 'Humus']*4/3/2 # new scaler\n",
    "\n",
    "# extract time info \n",
    "belgium['Profilering_Datum'] = belgium['Profilering_Datum'].str.split(' ').str[0]\n",
    "belgium['Profilering_Datum'] = belgium['Profilering_Datum'].str.split('-').str[-1].astype(float)\n",
    "belgium.loc[belgium['Profilering_Datum'] >2020, 'Profilering_Datum'] = np.nan\n",
    "\n",
    "# extract depth info\n",
    "belgium['hzn_top'] = np.nanmin(belgium[['Diepte_grens_boven1', 'Diepte_grens_boven2']], axis=1)\n",
    "belgium['hzn_btm'] = np.nanmax(belgium[['Diepte_grens_onder1', 'Diepte_grens_onder2']], axis=1)\n",
    "belgium.loc[belgium['hzn_top'] > belgium['hzn_btm'],['hzn_top','hzn_btm']] = np.nan\n",
    "\n",
    "column_names = ['lat','lon','time','hzn_top','hzn_btm','ref']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['time'] = belgium['Profilering_Datum']\n",
    "temp['hzn_top'] = belgium['Diepte_grens_boven1']\n",
    "temp['hzn_btm'] = belgium['Diepte_grens_onder1']\n",
    "temp.loc[temp['hzn_top'].isna(),'hzn_top'] = belgium.loc[temp['hzn_top'].isna(),'Diepte_grens_boven2']\n",
    "temp.loc[temp['hzn_btm'].isna(),'hzn_btm'] = belgium.loc[temp['hzn_btm'].isna(),'Diepte_grens_onder2']\n",
    "temp['hzn_top'] = belgium['hzn_top'] \n",
    "temp['hzn_btm'] = belgium['hzn_btm']   \n",
    "temp['lat'] = belgium['lat']\n",
    "temp['lon'] = belgium['lon']\n",
    "temp['oc'] = belgium['Humus']*10\n",
    "temp['caco3'] = belgium['Calciumcarbonaatgehalte']*10 # %->g/kg\n",
    "temp['N'] = np.nan\n",
    "temp['ph_kcl'] = belgium['pH_KCl']\n",
    "temp['ph_h2o'] = belgium['pH_H2O']\n",
    "temp['ph_cacl2'] = np.nan\n",
    "temp['bulk_density'] = np.nan\n",
    "temp['clay'] = belgium['T0_2']\n",
    "temp['silt'] = belgium['T2_10']+belgium['T10_20']+belgium['T20_50']\n",
    "temp['sand'] = belgium['T50_100']+belgium['T100_200']+belgium['T200_500']+belgium['T500_1000']+belgium['T1000_2000']\n",
    "temp['K'] = np.nan\n",
    "temp['P'] = np.nan\n",
    "temp['ref'] = 'vlaanderen.belgium'\n",
    "temp['nuts0'] = 'BE'\n",
    "\n",
    "# possible filter\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'{na} data with no time info')\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'{na} data with no depth info')\n",
    "\n",
    "na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "print(f'{na} data with no coordinate info')\n",
    "\n",
    "print(f'{len(temp)} in total')\n",
    "# temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/belgium_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884efdd0-e166-460b-a6ef-cdb9910b37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scotland\n",
    "# scotland = pd.read_excel('/mnt/diskstation/data/soil_points/Scotland/NSIS_1_10km_grid_gh.xlsx', sheet_name='NSIS1_10km')\n",
    "# osgb36 = pyproj.CRS.from_string(\"+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894 +units=m +no_defs\")\n",
    "# wgs84 = pyproj.CRS.from_epsg(4326)\n",
    "# transformer = pyproj.Transformer.from_crs(osgb36, wgs84)\n",
    "# scotland['lat'], scotland['lon'] = transformer.transform(scotland['EASTING'], scotland['NORTHING'])\n",
    "\n",
    "# column_names = ['lat','lon','time','hzn_top','hzn_btm','ref']\n",
    "# temp = pd.DataFrame(columns=column_names)\n",
    "# temp['lat'] = scotland['lat']\n",
    "# temp['lon'] = scotland['lon']\n",
    "# temp['nuts0'] = 'UK-scotland'\n",
    "# temp['time'] = scotland['PROFILE_DATE'].astype(str).str[-4:]\n",
    "# temp['hzn_top'] = scotland['HORZ_TOP']\n",
    "# temp['hzn_btm'] = scotland['HORZ_BOTTOM']\n",
    "# temp['ref'] = 'scotland.NSIS1-hutton.ac.uk'\n",
    "\n",
    "# temp['oc'] = scotland['DP1971_ORGANIC_MATTER']*10/1.72\n",
    "# temp['N'] = scotland['DP1971_NITROGEN']*10 # % -> g/kg\n",
    "# temp['caco3'] = np.nan\n",
    "# temp['bulk_density'] = np.nan\n",
    "# temp['ph_kcl'] = np.nan\n",
    "# temp['ph_h2o'] = scotland['DP1971_PH_H2O']\n",
    "# temp['ph_cacl2'] = scotland['DP1971_PH_CACL2']\n",
    "# temp['clay'] = scotland['DP1971_CLAY']\n",
    "# temp['silt'] = scotland['DP1971_UBSILT']\n",
    "# temp['sand'] = scotland['DP1971_UBSAND']\n",
    "# temp['K'] = scotland['NIPAQUA_POTASSIUM'] # ppm = mg/kg\n",
    "# temp['P'] = scotland['NIPAQUA_PHOSPHORUS'] # ppm = mg/kg\n",
    "\n",
    "# # possible filter\n",
    "# na = temp['time'].isna().sum()\n",
    "# print(f'{na} data with no time info')\n",
    "\n",
    "# na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "# print(f'{na} data with no depth info')\n",
    "\n",
    "# na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "# print(f'{na} data with no coordinate info')\n",
    "\n",
    "# print(f'{len(temp)} in total')\n",
    "\n",
    "# # temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/scotland_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da958f00-e769-40f4-800e-02155ed9fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 data with no time info\n",
      "0 data with no depth info\n",
      "0 data with no coordinate info\n",
      "3015 in total\n"
     ]
    }
   ],
   "source": [
    "# estonia\n",
    "# estonia = gpd.read_file('/mnt/diskstation/data/soil_points/Estonia/export_estonia_public_soil_samples.gpkg')\n",
    "temp = pd.read_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/estonia_harmonized_v1.csv')\n",
    "temp['ref'] = 'estonia.kese'\n",
    "temp['nuts0'] = 'EE'\n",
    "# column_names = ['lat','lon','time','hzn_top','hzn_btm','ref']\n",
    "# temp = pd.DataFrame(columns=column_names)\n",
    "# temp['lat'] = estonia['geometry'].y\n",
    "# temp['lon'] = estonia['geometry'].x\n",
    "# temp['nuts0'] = 'EE'\n",
    "# # temp['time'] = estonia['PROFILE_DATE'].astype(str).str[-4:]\n",
    "# temp['hzn_top'] = estonia['soil_depth']-1\n",
    "# temp['hzn_btm'] = estonia['soil_depth']+1\n",
    "# temp.loc[estonia['soil_depth'].isna(),'hzn_top'] = 0\n",
    "# temp.loc[estonia['soil_depth'].isna(),'hzn_btm'] = 25\n",
    "# temp['ref'] = 'https://www.hutton.ac.uk/about/facilities/national-soils-archive/resampling-soils-inventory'\n",
    "\n",
    "# temp['oc'] = estonia['SOC']*10 # % -> g/kg\n",
    "# # temp['N'] = estonia['DP1971_NITROGEN']*10 # % -> g/kg\n",
    "# # temp['caco3'] = np.nan\n",
    "# # temp['bulk_density'] = np.nan\n",
    "# # temp['ph_kcl'] = np.nan\n",
    "# # temp['ph_h2o'] = estonia['DP1971_PH_H2O']\n",
    "# # temp['ph_cacl2'] = estonia['DP1971_PH_CACL2']\n",
    "# # temp['clay'] = estonia['DP1971_CLAY']\n",
    "# # temp['silt'] = estonia['DP1971_UBSILT']\n",
    "# # temp['sand'] = estonia['DP1971_UBSAND']\n",
    "# # temp['K'] = estonia['NIPAQUA_POTASSIUM'] # ppm = mg/kg\n",
    "# # temp['P'] = estonia['NIPAQUA_PHOSPHORUS'] # ppm = mg/kg\n",
    "\n",
    "# possible filter\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'{na} data with no time info')\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'{na} data with no depth info')\n",
    "\n",
    "na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "print(f'{na} data with no coordinate info')\n",
    "\n",
    "print(f'{len(temp)} in total')\n",
    "temp\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/estonia_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949eeee7-a316-40a0-980e-71bdf4d255b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /opt/conda/share/proj failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 data with no time info\n",
      "0 data with no depth info\n",
      "1 data with no coordinate info\n",
      "4132 in total\n"
     ]
    }
   ],
   "source": [
    "# gema\n",
    "gema = gpd.read_file('/mnt/diskstation/data/soil_points/EU/GEMAS/GEMAS.csv')\n",
    "\n",
    "column_names = ['lat','lon','time','hzn_top','hzn_btm','ref']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['lat'] = gema['YCOO']\n",
    "temp['lon'] = gema['XCOO']\n",
    "temp['oc'] = gema['TOC'] \n",
    "temp['ph_cacl2'] = gema['pH_CaCl2']\n",
    "temp['clay'] = gema['clay']\n",
    "temp['silt'] = gema['silt']\n",
    "temp['time'] = 2008\n",
    "temp['hzn_top'] = gema['UHDICM']\n",
    "temp['hzn_btm'] = gema['LHDICM']\n",
    "temp = temp.apply(pd.to_numeric)\n",
    "temp['sand'] = 100-temp['clay']-temp['silt']\n",
    "temp['oc'] = temp['oc']*10 # % -> g/kg\n",
    "\n",
    "country_to_nuts0 = {\n",
    "    'GER': 'DE',  # Germany\n",
    "    'SKA': 'SK',  # Slovakia\n",
    "    'EST': 'EE',  # Estonia\n",
    "    'LIT': 'LT',  # Lithuania\n",
    "    'NOR': 'NO',  # Norway (Note: Norway is not an EU member but is included in some NUTS classifications)\n",
    "    'PTG': 'PT',  # Portugal\n",
    "    'POL': 'PL',  # Poland\n",
    "    'SWE': 'SE',  # Sweden\n",
    "    'DEN': 'DK',  # Denmark\n",
    "    'ITA': 'IT',  # Italy\n",
    "    'FRA': 'FR',  # France\n",
    "    'FIN': 'FI',  # Finland\n",
    "    'UKR': 'UA',  # Ukraine (Note: Ukraine is not an EU member and typically not included in NUTS)\n",
    "    'CRO': 'HR',  # Croatia\n",
    "    'HEL': 'EL',  # Greece (Note: The code for Greece in the NUTS classification is EL, not GR)\n",
    "    'HUN': 'HU',  # Hungary\n",
    "    'SPA': 'ES',  # Spain\n",
    "    'CYP': 'CY',  # Cyprus\n",
    "    'BEL': 'BE',  # Belgium\n",
    "    'UNK': 'UK',  # United Kingdom (Note: The UK left the EU but was previously included in NUTS)\n",
    "    'LAV': 'LV',  # Latvia\n",
    "    'SIL': 'SI',  # Slovenia\n",
    "    'BUL': 'BG',  # Bulgaria\n",
    "    'SRB': 'RS',  # Serbia (Note: Serbia is a candidate country for EU membership)\n",
    "    'CZR': 'CZ',  # Czech Republic\n",
    "    'BOS': 'BA',  # Bosnia and Herzegovina (Note: Bosnia and Herzegovina is not an EU member)\n",
    "    'FOM': 'MK',  # North Macedonia (Note: The official NUTS code for North Macedonia is MK)\n",
    "    'AUS': 'AT',  # Austria\n",
    "    'NEL': 'NL',  # Netherlands\n",
    "    'SLO': 'SK',  # Slovakia (Note: This seems to be a duplicate of SKA)\n",
    "    'IRL': 'IE',  # Ireland\n",
    "    'MON': 'ME',  # Montenegro (Note: Montenegro is a candidate country for EU membership)\n",
    "    'LUX': 'LU'   # Luxembourg\n",
    "}\n",
    "\n",
    "temp['nuts0'] = gema['COUNTRY']\n",
    "temp['nuts0'] = temp['nuts0'].map(country_to_nuts0)\n",
    "temp['ref'] = 'gemas'\n",
    "temp['lc_survey'] = gema['TYPE']\n",
    "temp.loc[temp['lc_survey']=='Gr','lc_survey'] = 'permanent grassland'\n",
    "temp.loc[temp['lc_survey']=='Ap','lc_survey'] = 'arable land'\n",
    "\n",
    "# possible filter\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'{na} data with no time info')\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'{na} data with no depth info')\n",
    "\n",
    "na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "print(f'{na} data with no coordinate info')\n",
    "\n",
    "print(f'{len(temp)} in total')\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/gemas_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f06af08-879e-4153-966b-f347907a80f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 data with no time info\n",
      "0 data with no depth info\n",
      "0 data with no coordinate info\n",
      "4148 in total\n"
     ]
    }
   ],
   "source": [
    "# france\n",
    "france = pd.read_csv('/mnt/diskstation/data/Soil_points/France/RMQS1_analyses_composites_18_11_2021_virgule.csv')\n",
    "rgf93 = pyproj.CRS.from_epsg(2154)  # RGF 93 coordinate system\n",
    "wgs84 = pyproj.CRS.from_epsg(4326)  # WGS84 (GPS) coordinate system\n",
    "transformer = pyproj.Transformer.from_crs(rgf93, wgs84)\n",
    "france['lat'],france['lon'] = transformer.transform(france['x_theo'], france['y_theo'])\n",
    "\n",
    "column_names = ['lat','lon','time','hzn_top','hzn_btm','ref']\n",
    "temp = pd.DataFrame(columns=column_names)\n",
    "temp['lat'] = france['lat']\n",
    "temp['lon'] = france['lon']\n",
    "temp['nuts0'] = 'FR'\n",
    "temp['time'] = france['date_complete'].str[0:4].astype(float)\n",
    "france = france.apply(pd.to_numeric, errors='coerce')\n",
    "temp['hzn_top'] = france['profondeur_hz_sup']\n",
    "temp['hzn_btm'] = france['profondeur_hz_inf']\n",
    "temp['ref'] = 'france.RMQS'\n",
    "temp['oc'] = france['carbone_16_5_1']\n",
    "temp['N'] = france['n_tot_31_1'] \n",
    "temp['caco3'] = france['calc_tot_2_1_2']\n",
    "temp['bulk_density'] = np.nan\n",
    "temp['ph_kcl'] = np.nan\n",
    "temp['ph_h2o'] = france['ph_eau_6_1']\n",
    "temp['ph_cacl2'] = np.nan\n",
    "temp['clay'] = france['argile']/10 # g/kg -> %\n",
    "temp['silt'] = (france['limon_fin']+france['limon_grossier'])/10 # g/kg -> %\n",
    "temp['sand'] = (france['sable_fin']+france['sable_grossier'])/10 # g/kg -> %\n",
    "temp['K'] = france['k_tot_hf']*10000 # g/100g -> mg/kg\n",
    "temp['P'] = france['p_ass_81_1']*1000 # olsen  g/kg -> mg/kg\n",
    "\n",
    "# possible filter\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'{na} data with no time info')\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'{na} data with no depth info')\n",
    "\n",
    "na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "print(f'{na} data with no coordinate info')\n",
    "\n",
    "print(f'{len(temp)} in total')\n",
    "\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/france_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81fb14af-e26c-45c0-8dd8-581aff68b3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 data with no time info\n",
      "0 data with no depth info\n",
      "0 data with no coordinate info\n",
      "36031 in total\n"
     ]
    }
   ],
   "source": [
    "# swiss\n",
    "temp = pd.read_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/swiss_harmonized_v1.csv')\n",
    "temp['ref'] = 'swiss.nabo'\n",
    "temp['nuts0'] = 'CH'\n",
    "\n",
    "# possible filter\n",
    "na = temp['time'].isna().sum()\n",
    "print(f'{na} data with no time info')\n",
    "\n",
    "na = len(temp[temp['hzn_btm'].isna() | temp['hzn_top'].isna()])\n",
    "print(f'{na} data with no depth info')\n",
    "\n",
    "na = len(temp[temp['lat'].isna() | temp['lon'].isna()])\n",
    "print(f'{na} data with no coordinate info')\n",
    "\n",
    "print(f'{len(temp)} in total')\n",
    "\n",
    "temp = temp.drop(columns=['anonymization','date'])\n",
    "temp.to_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/swiss_harmonized_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96b819-b469-4158-8dd6-ede2755cbeda",
   "metadata": {},
   "source": [
    "### merge the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "707a044e-ee44-4212-8e2e-91c641df49d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "germany:17189\n",
      "swiss:36031\n",
      "croatia:6271\n",
      "estonia:3015\n",
      "france:4148\n",
      "gemas:4132\n",
      "lucas: 75426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1792382/2003042062.py:12: DtypeWarning: Columns (7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lucas = pd.read_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/lucas.full_harmonized_v1.csv')\n"
     ]
    }
   ],
   "source": [
    "# merge all the data\n",
    "names = ['germany','swiss','croatia','estonia','france','gemas'] #'belgium','ireland','scotland'\n",
    "column_names = ['lat', 'lon', 'time', 'hzn_top', 'hzn_btm', 'ref', 'oc', 'ph_h2o', \n",
    "                'ph_cacl2', 'bulk_density', 'clay', 'silt', 'sand', 'caco3', 'N', 'K', 'P']\n",
    "data = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for i in names:\n",
    "    temp = pd.read_csv(f'/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/{i}_harmonized_v1.csv')\n",
    "    print(f'{i}:{len(temp)}')\n",
    "    data = pd.concat([data,temp])\n",
    "    \n",
    "lucas = pd.read_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/lucas.full_harmonized_v1.csv')\n",
    "print(f'lucas: {len(lucas)}')\n",
    "data = pd.concat([data,lucas])\n",
    "data = data.drop(columns=['point_id','lc_survey','ph_kcl','ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da404223-c9af-4215-97c7-2554580336d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat: missing 0 data, 0%\n",
      "lon: missing 0 data, 0%\n",
      "time: missing 0 data, 0%\n",
      "hzn_top: missing 0 data, 0%\n",
      "hzn_btm: missing 0 data, 0%\n",
      "ref: missing 0 data, 0%\n",
      "oc: missing 16259 data, 14%\n",
      "ph_h2o: missing 27763 data, 25%\n",
      "ph_cacl2: missing 23308 data, 21%\n",
      "bulk_density: missing 80274 data, 71%\n",
      "clay: missing 55162 data, 49%\n",
      "silt: missing 55237 data, 49%\n",
      "sand: missing 55860 data, 49%\n",
      "caco3: missing 52402 data, 46%\n",
      "N: missing 26201 data, 23%\n",
      "K: missing 41826 data, 37%\n",
      "P: missing 45943 data, 41%\n",
      "nuts0: missing 0 data, 0%\n"
     ]
    }
   ],
   "source": [
    "# only keep the data measured after 2000\n",
    "data = data.loc[data['time']>=2000]\n",
    "\n",
    "# drop rows without coordinates recorded\n",
    "data = data.loc[~data['lat'].isna()]\n",
    "\n",
    "# overview of the dataset\n",
    "for col in data.columns.values.tolist():\n",
    "    print(f'{col}: missing {data[col].isna().sum()} data, {round(data[col].isna().sum()*100/len(data))}%')\n",
    "    \n",
    "data.to_csv(f'/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/soil.full_harmonized_v1.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7210da4d-8f08-4bae-9635-b5fb5ebf46bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create gpkg\n",
    "# from shapely.geometry import Point\n",
    "# from geopandas import gpd\n",
    "\n",
    "# df = pd.read_csv('/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/training_point_v2_full.csv', low_memory=False)\n",
    "# geometry = [Point(xy) for xy in zip(df['gps_long'], df['gps_lat'])]\n",
    "# gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# gdf_3035 = gdf.to_crs(\"EPSG:3035\")\n",
    "# gdf_3035['point_index'] = gdf_3035.index\n",
    "# gdf_3035.to_file(\"/mnt/primus/xuemeng_tmp_harbour/soc_eu/data/training_point_overlay_3035.gpkg\", driver=\"GPKG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "25482bed-ebf2-4e4e-b30e-dec3f5b10ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224d4b3-2d9b-4d46-bd71-d76511cd799f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
