{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9305d568-6e58-4aea-9467-5eb3341f7d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opengeohub/.local/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.3-CAPI-1.17.3) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from eumap.misc import find_files, nan_percentile, GoogleSheet, ttprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GroupKFold\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tool_kit import calc_ccc, accuracy_plot, uncertainty_plot\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, HalvingGridSearchCV, KFold, GroupKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# read in necessary material\n",
    "folder = '/mnt/inca/soc_eu_model'\n",
    "test = pd.read_csv(f'{folder}/data/004.0_validate.pnts_oc.csv',low_memory=False)\n",
    "train = pd.read_csv(f'{folder}/data/005.0_train.pnts_oc.csv',low_memory=False)\n",
    "\n",
    "# covariates\n",
    "with open(f'{folder}/SOC-EU/features/002_selected.covar_rank.freq.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "covs = [line.strip() for line in lines]\n",
    "\n",
    "# dataset\n",
    "train = train.dropna(subset=covs,how='any')\n",
    "test = test.dropna(subset=covs,how='any')\n",
    "\n",
    "# target variable\n",
    "tgt = 'oc_log1p'\n",
    "\n",
    "# spatial cross validation\n",
    "spatial_cv_column = 'tile_id'\n",
    "cv = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a35eda-9324-41bf-89a5-879e0ce6f64a",
   "metadata": {},
   "source": [
    "### Parameter fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb95e2d-9c21-4c55-ac64-df25d5b96070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:16:45] start parameter fine tuning for rf, training size: 99126\n",
      "n_iterations: 5\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 407\n",
      "max_resources_: 99126\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 540\n",
      "n_resources: 407\n",
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 180\n",
      "n_resources: 1221\n",
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 60\n",
      "n_resources: 3663\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 20\n",
      "n_resources: 10989\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 7\n",
      "n_resources: 32967\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[10:46:36] Finish fine tuning\n",
      "Best parameters found:  {'max_depth': 30, 'max_features': 0.3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/inca/soc_eu_model/SOC-EU/model/002_model_rf.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# random forest\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500, 800, 1000],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'max_features': [0.3, 0.5, 0.7, 'log2', 'sqrt'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "tune_rf = HalvingGridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=90, \n",
    "    cv=cv,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ttprint(f'start parameter fine tuning for rf, training size: {len(train)}')\n",
    "tune_rf.fit(train[covs], train[tgt], groups=train[spatial_cv_column])\n",
    "ttprint(\"Finish fine tuning\\nBest parameters found: \", tune_rf.best_params_)\n",
    "joblib.dump(tune_rf.best_params_, f'{folder}/SOC-EU/model/001_best.params_rf.joblib')\n",
    "joblib.dump(tune_rf.best_estimator_, f'{folder}/SOC-EU/model/002_model_rf.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae11d74-c1df-49cd-a471-2c9277949feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:46:53] start parameter fine tuning for Lasso, training size: 99126\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 33042\n",
      "max_resources_: 99126\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 6\n",
      "n_resources: 33042\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 99126\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[10:50:03] Finish fine tuning\n",
      "Best parameters found:  {'alpha': 0.001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/inca/soc_eu_model/SOC-EU/model/004_model_lasso.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lasso linear regression\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "tune_lasso = HalvingGridSearchCV(\n",
    "    estimator=Lasso(),\n",
    "    param_grid=param_grid_lasso,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ttprint(f'start parameter fine tuning for Lasso, training size: {len(train)}')\n",
    "tune_lasso.fit(train[covs], train[tgt], groups=train[spatial_cv_column])\n",
    "ttprint(\"Finish fine tuning\\nBest parameters found: \", tune_lasso.best_params_)\n",
    "joblib.dump(tune_lasso.best_params_, f'{folder}/SOC-EU/model/003_best.params_lasso.joblib')\n",
    "joblib.dump(tune_lasso.best_estimator_, f'{folder}/SOC-EU/model/004_model_lasso.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9574838-a3e2-456c-a450-3d4cc711065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:28] start parameter fine tuning for ANN, training size: 99126\n",
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 1223\n",
      "max_resources_: 99126\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 192\n",
      "n_resources: 1223\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 64\n",
      "n_resources: 3669\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 22\n",
      "n_resources: 11007\n",
      "Fitting 3 folds for each of 22 candidates, totalling 66 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 8\n",
      "n_resources: 33021\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 3\n",
      "n_resources: 99063\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[21:47:31] Finish fine tuning\n",
      "Best parameters found:  {'mlp__activation': 'tanh', 'mlp__alpha': 0.001, 'mlp__hidden_layer_sizes': (100, 100), 'mlp__learning_rate': 'constant', 'mlp__learning_rate_init': 0.01, 'mlp__solver': 'sgd'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/inca/soc_eu_model/SOC-EU/model/006_model_ann.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple ANN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', MLPRegressor(max_iter=5000, early_stopping=True, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_ann = {\n",
    "    'mlp__hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100)],  # NN structure\n",
    "    'mlp__activation': ['tanh', 'relu'],  # commonly used activation functions in NN\n",
    "    'mlp__solver': ['adam', 'sgd'],  # optimizer\n",
    "    'mlp__alpha': [0.0001, 0.001, 0.01],  # regularization to prevent overfitting\n",
    "    'mlp__learning_rate': ['constant', 'adaptive'],  # how aggressive the weights update\n",
    "    'mlp__learning_rate_init': [0.001, 0.01]  # initial learning rate\n",
    "}\n",
    "\n",
    "# Define the HalvingGridSearchCV with the pipeline\n",
    "tune_ann = HalvingGridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid_ann,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "ttprint(f'start parameter fine tuning for ANN, training size: {len(train)}')\n",
    "tune_ann.fit(train[covs], train[tgt], groups=train[spatial_cv_column])\n",
    "ttprint(\"Finish fine tuning\\nBest parameters found: \", tune_ann.best_params_)\n",
    "\n",
    "joblib.dump(tune_ann.best_params_, f'{folder}/SOC-EU/model/005_best.params_ann.joblib')\n",
    "joblib.dump(tune_ann.best_estimator_, f'{folder}/SOC-EU/model/006_model_ann.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f85a07-dd30-4f88-acb1-e6f3e5f5e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cubist import Cubist\n",
    "# https://pypi.org/project/cubist/\n",
    "# rule-based predictive model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "import joblib\n",
    "from cubist import Cubist\n",
    "\n",
    "# Define a pipeline that includes scaling and the Cubist model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('cubist', Cubist())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for Cubist within the pipeline\n",
    "param_cubist = {\n",
    "    'cubist__n_rules': [100, 300, 500],  # number of rules to be generated\n",
    "    'cubist__n_committees': [1, 5, 10],  # committee: ensembles of models\n",
    "    'cubist__neighbors': [None, 3, 6, 9],  # number of nearest neighbors to use when making a prediction\n",
    "    'cubist__unbiased': [False, True],  # whether or not to use an unbiased method of rule generation\n",
    "    'cubist__extrapolation': [0.02, 0.05],  # limits the extent to which predictions can extrapolate beyond the range of the training data, a fraction of the total range of the target variable\n",
    "    'cubist__sample': [None, 0.1, 0.5]  # fraction of the training data used in building each model\n",
    "}\n",
    "\n",
    "# Define the HalvingGridSearchCV with the pipeline\n",
    "tune_cubist = HalvingGridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_cubist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=90,\n",
    "    cv=cv\n",
    ")\n",
    "\n",
    "# Ensure the data retains feature names\n",
    "X_train = pd.DataFrame(train[covs].values, columns=covs)\n",
    "y_train = train[tgt]\n",
    "\n",
    "# Start fine-tuning process\n",
    "ttprint('start fine tuning cubist')\n",
    "tune_cubist.fit(X_train, y_train, groups=train[spatial_cv_column])\n",
    "ttprint(\"Finish fine tuning\\nBest parameters found: \", tune_cubist.best_params_)\n",
    "\n",
    "# Save the best parameters and model\n",
    "joblib.dump(tune_cubist.best_params_, f'{folder}/SOC-EU/model/007_best.params_cubist.joblib')\n",
    "joblib.dump(tune_cubist.best_estimator_, f'{folder}/SOC-EU/model/008_model_cubist.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2067a2-4cc9-4887-95bf-2db57f4c60e1",
   "metadata": {},
   "source": [
    "### enxemble machine learning\n",
    "- loop through each possible combination\n",
    "- record the metrics\n",
    "- select the optimal combination of model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d07b6-17dc-4adf-9afb-bd71f9c8f153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/inca/soc_eu_model/SOC-EU/model/002_model_rf.joblib', '/mnt/inca/soc_eu_model/SOC-EU/model/004_model_lasso.joblib', '/mnt/inca/soc_eu_model/SOC-EU/model/006_model_ann.joblib', '/mnt/inca/soc_eu_model/SOC-EU/model/008_model_cubist.joblib']\n",
      "[07:17:21] fitting rf + lasso\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tool_kit import calc_ccc, accuracy_plot, uncertainty_plot\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Load models\n",
    "model_list = find_files(f'{folder}/SOC-EU/model/','0*model*.joblib')\n",
    "model_list = [str(i) for i in model_list]\n",
    "models = [joblib.load(path) for path in model_list]\n",
    "model_names = [\"rf\", \"lasso\", \"ann\", \"cubist\"]\n",
    "print(model_list)\n",
    "\n",
    "# Generate all combinations of models (2, 3, and 4)\n",
    "combinations = []\n",
    "for r in range(2, 5):\n",
    "    combinations.extend(itertools.combinations(zip(models, model_names), r))\n",
    "    \n",
    "# training dataset\n",
    "sampled_train = train.groupby(spatial_cv_column, group_keys=False).apply(lambda x: x.sample(min(len(x), 10))) # 44% data\n",
    "\n",
    "results = []\n",
    "# Loop through each combination of models\n",
    "for combination in combinations:\n",
    "    estimators = [(name, model) for model, name in combination]\n",
    "    combi_name = ''\n",
    "    for _, name in combination:\n",
    "        combi_name = combi_name+' + '+name\n",
    "    combi_name = combi_name[3::]\n",
    "    if 'rf' not in combi_name:\n",
    "        continue\n",
    "    \n",
    "    ttprint(f'fitting {combi_name}')\n",
    "    # Define the Stacking Regressor\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LinearRegression()\n",
    "    )\n",
    "    \n",
    "    # Fit the stacking regressor\n",
    "#     y_pred = cross_val_predict(stacking_regressor, sampled_train[covs], sampled_train[tgt], cv=cv, groups=sampled_train[spatial_cv_column], n_jobs=90)  \n",
    "    stacking_regressor.fit(sampled_train[covs], sampled_train[tgt])\n",
    "    ttprint('finish fitting')\n",
    "    y_pred = stacking_regressor.predict(test[covs])\n",
    "    r2, rmse, ccc = accuracy_plot(test[tgt], y_pred, combi_name) # visuliazation\n",
    "    error_spatial_plot(test[tgt], y_pred, test['lat'], test['lon'], combi_name)\n",
    "    sorted_plot(test[tgt],y_pred,combi_name)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        \"Models\": combi_name,\n",
    "        \"R2_CV\": r2,\n",
    "        \"RMSE_CV\": rmse,\n",
    "        \"CCC_CV\": ccc\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.to_csv(f'{folder}/SOC-EU/model/011_metrics_cv.eml.csv', index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb26ca-aec2-40be-ad36-bed8888bab90",
   "metadata": {},
   "source": [
    "### mapie build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84df759-50bc-43c7-9287-a407a1a1889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapie = MapieRegressor(model, method=\"minmax\", cv=5, n_jobs=90) # this cv is to compute the conformal scores, and spatial cross validation\n",
    "mapie.fit(X[covs], X[tgt], groups=X[spatial_cv_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54dd6a5a-a9d7-4139-a5c1-cdb749245e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train = train.groupby(spatial_cv_column, group_keys=False).apply(lambda x: x.sample(frac=0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be51dd87-bb70-4166-a8e1-b1f1d17b5d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5481\n",
      "5481\n"
     ]
    }
   ],
   "source": [
    "print(len(sampled_train[spatial_cv_column].unique())) \n",
    "print(len(train[spatial_cv_column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e81c62-0318-4891-b8f5-60e7653556f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a361f4-2415-4f1a-9073-379debe78781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4473296612392309"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_train)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936269a-7865-4073-9b13-0d44f69f4299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
