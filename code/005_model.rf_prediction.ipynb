{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9305d568-6e58-4aea-9467-5eb3341f7d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opengeohub/.local/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.3-CAPI-1.17.3) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from eumap.misc import find_files, nan_percentile, GoogleSheet, ttprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GroupKFold\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tool_kit import calc_ccc, accuracy_plot\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, HalvingGridSearchCV, KFold, GroupKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # model parameters\n",
    "# import json\n",
    "# with open('/mnt/inca/soc_eu_model/data/006_params_annual.json', 'r') as file:\n",
    "#     params = json.load(file)\n",
    "\n",
    "# train\n",
    "folder = '/mnt/inca/soc_eu_model'\n",
    "df = pd.read_csv(f'{folder}/data_history/005.0_train.pnts_soc.csv',low_memory=False)\n",
    "# target\n",
    "train = df.loc[df['oc'].notna()]\n",
    "train = train.loc[train['oc']>6]\n",
    "train = train.loc[train['ref']!='nl.bis'] # show weird patterns\n",
    "train.loc[:,'oc_log1p'] = np.log1p(train['oc'])\n",
    "tgt = 'oc_log1p'\n",
    "\n",
    "# test\n",
    "dff = pd.read_csv(f'{folder}/data_history/004.0_validate.pnts_soc.csv',low_memory=False)\n",
    "# target\n",
    "test = dff.loc[dff['oc'].notna()]\n",
    "test = test.loc[test['oc']>5]\n",
    "test = test.loc[test['ref']!='nl.bis'] # data from nl.bis show weird patterns\n",
    "test.loc[:,'oc_log1p'] = np.log1p(test['oc'])\n",
    "\n",
    "# covariates\n",
    "with open(f'{folder}/SOC-EU/features/002_selected.covar_rank.freq.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "covs = [line.strip() for line in lines]\n",
    "train = train.dropna(subset=covs,how='any')\n",
    "test = test.dropna(subset=covs,how='any')\n",
    "\n",
    "spatial_cv_column = 'tile_id'\n",
    "cv = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a35eda-9324-41bf-89a5-879e0ce6f64a",
   "metadata": {},
   "source": [
    "### Parameter fine tuning for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb95e2d-9c21-4c55-ac64-df25d5b96070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:47:45] start parameter fine tuning for rf, training size: 129109\n",
      "n_iterations: 5\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 531\n",
      "max_resources_: 129109\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 540\n",
      "n_resources: 531\n",
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 180\n",
      "n_resources: 1593\n",
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 60\n",
      "n_resources: 4779\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 20\n",
      "n_resources: 14337\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 7\n",
      "n_resources: 43011\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[11:22:14] Finish fine tuning\n",
      "Best parameters found:  {'max_depth': 30, 'max_features': 0.3, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 800}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/inca/soc_eu_model/SOC-EU/model/002_model_rf.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# https://zillow.github.io/quantile-forest/user_guide/fit_predict.html#random-forest-predictions\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500, 800, 1000],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'max_features': [0.3, 0.5, 0.7, 'log2', 'sqrt'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "tune_rf = HalvingGridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=90, \n",
    "    cv=cv,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ttprint(f'start parameter fine tuning for rf, training size: {len(train)}')\n",
    "tune_rf.fit(train[covs], train[tgt], groups=train[spatial_cv_column])\n",
    "ttprint(\"Finish fine tuning\\nBest parameters found: \", tune_rf.best_params_)\n",
    "joblib.dump(tune_rf.best_params_, f'{folder}/SOC-EU/model/001_best.params_rf.joblib')\n",
    "joblib.dump(tune_rf.best_estimator_, f'{folder}/SOC-EU/model/002_model_rf.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc5e23-4c7d-45d4-a5d4-c22bf410225c",
   "metadata": {},
   "source": [
    "### test different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f543fd-a9d2-46fa-ab3e-fe74345e945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from mapie.metrics import regression_coverage_score\n",
    "from tool_kit import calc_ccc, accuracy_plot\n",
    "from mapie.regression import MapieQuantileRegressor, MapieRegressor\n",
    "\n",
    "model_params = joblib.load(f'{folder}/SOC-EU/model/001_best.params_rf.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4fb8d-c582-43f2-96bf-3e2a48dfa6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:01:02] start fitting model\n",
      "[06:02:19] finish fitting model\n",
      "[06:02:19] start fitting mapie\n",
      "[06:08:55] finish fitting mapie\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title = 'qa_higher_than_5'\n",
    "\n",
    "train_t = train\n",
    "\n",
    "model = RandomForestRegressor(**model_params, n_jobs=80)\n",
    "    \n",
    "ttprint('start fitting model')\n",
    "model.fit(train_t[covs],train_t[tgt])\n",
    "ttprint('finish fitting model')\n",
    "    \n",
    "ttprint('start fitting mapie')\n",
    "mapie = MapieRegressor(model, method=\"plus\", cv=5) # this cv is to compute the conformal scores\n",
    "mapie.fit(train_t[covs], train_t[tgt])\n",
    "ttprint('finish fitting mapie')\n",
    "        \n",
    "joblib.dump(model, f'{folder}/SOC-EU/model/test_rf_{title}.joblib')\n",
    "joblib.dump(mapie, f'{folder}/SOC-EU/model/test_rf.mapie_{title}.joblib')\n",
    "        \n",
    "y_pred, y_pis = mapie.predict(test[covs], alpha=0.1) # 90% prediction interval \n",
    "accuracy_plot(test[tgt], y_pred, title_text=f'rf - {title}')\n",
    "\n",
    "#     y_pred = model.predict(test[covs])\n",
    "ccc = calc_ccc(test[tgt], y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(test[tgt], y_pred))\n",
    "r2 = r2_score(test[tgt], y_pred)\n",
    "picp = np.mean((test[tgt] >= y_pis[:, 0, 0]) & (test[tgt] <= y_pis[:, 1, 0]))\n",
    "pi_width = np.mean(y_pis[:, 1, 0] - y_pis[:, 0, 0])\n",
    "\n",
    "print(f\"Concordance Correlation Coefficient (CCC): {ccc:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n",
    "print(f\"Prediction Interval Coverage Probability (PICP): {picp:.4f}\")\n",
    "print(f\"Prediction Interval Width (PI Width): {pi_width:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b39d7-b8c3-4bca-ae0e-609c58643248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
