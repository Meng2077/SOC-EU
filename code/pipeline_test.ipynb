{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1191b271-c177-4487-95d5-ad80da6e4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess as mp\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from eumap.misc import find_files\n",
    "from eumap.raster import read_rasters, save_rasters\n",
    "from eumap.mapper import SpaceOverlay\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "import pyproj\n",
    "from shapely.geometry import Point\n",
    "from eumap.mapper import LandMapper\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, HalvingGridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2faf2c-df7e-44c9-a669-c48fe6e9f7fc",
   "metadata": {},
   "source": [
    "### feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b65fc4-a546-4de5-8612-84a12dd3a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up cross-validation\n",
    "# kf = KFold(n_splits=num_iterations, shuffle=True, random_state=42)\n",
    "# score = pd.DataFrame()\n",
    "# score['feat_num'] = np.arange(10,df.shape[1]+1,10)\n",
    "\n",
    "# for fold_idx, (train_idx, _) in enumerate(kf.split(x)):  # Replace X with your data\n",
    "\n",
    "#     x_subset = x[train_idx]\n",
    "#     y_subset = y[train_idx]  \n",
    "    \n",
    "#     # Initialize RFECV\n",
    "#     rfecv = RFECV(estimator=RandomForestRegressor(), step=10, cv=5, min_features_to_select=10, scoring='neg_mean_squared_error')\n",
    "#     rfecv.fit(x_subset, y_subset)\n",
    "\n",
    "#     cname = 'score_fold' + f'{str(fold_idx+1)}'\n",
    "#     score[cname] = rfecv.grid_scores_\n",
    "#     plt.plot(score['feat_num'], score[cname], marker='o')\n",
    "#     plt.xlabel('Number of Features')\n",
    "#     plt.ylabel('Cross-Validation Negative Mean Squared Error')\n",
    "#     plt.title(f'Scree Plot for Fold {fold_idx + 1}')\n",
    "#     plt.show()\n",
    "\n",
    "# # find the best number-of-feature\n",
    "# best_feature_numbers = []\n",
    "# for fold_idx in range(num_iterations):\n",
    "#     cname = 'score_fold' + f'{str(fold_idx+1)}'\n",
    "#     best_feature_index = score[cname].idxmax()\n",
    "#     best_feature_number = score.iloc[best_feature_index]['feat_num']\n",
    "#     best_feature_numbers.append(best_feature_number)\n",
    "\n",
    "# nof = round(np.mean(best_feature_numbers))\n",
    "# print(\"Best feature numbers for each fold:\", best_feature_numbers)\n",
    "# print(f\"Average: {np.mean(best_feature_numbers)}\")\n",
    "\n",
    "\n",
    "# Set up cross-validation\n",
    "score = pd.DataFrame()\n",
    "score['feat_num'] = np.arange(10,df.shape[1]+1,10)\n",
    "\n",
    "rfecv = RFECV(estimator=RandomForestRegressor(), step=10, cv=5, min_features_to_select=10, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(x_subset, y_subset)\n",
    "\n",
    "score['score'] = rfecv.grid_scores_\n",
    "plt.plot(score['feat_num'], score['score'], marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cross-Validation Negative Mean Squared Error')\n",
    "plt.title(f'Scree Plot')\n",
    "plt.show()\n",
    "\n",
    "best_feature_index = score['score'].idxmax()\n",
    "best = score.iloc[best_feature_index]['feat_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82166fbe-aac7-43f4-8424-7e0079acd681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the final feature selection\n",
    "estimator = RandomForestClassifier(random_state=11)\n",
    "rfecv = RFECV(estimator=estimator, step=10, cv=5, min_features_to_select=best, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(x, y)\n",
    "x_selected = rfecv.fit_transform(x, y)\n",
    "x_selected.to_csv('pipeline/oc_selected_v1.csv')\n",
    "score.to_csv('pipeline/eval_mat_score.vs.featnum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c4ba49-efa3-4a03-b376-424e263d6597",
   "metadata": {},
   "source": [
    "### hyperparameter Tuning for Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bc3c8-adc1-40cd-b3c5-2823a833bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Hyperparameter Tuning for Base Learners\n",
    "models = ['rf','gbr','lr','ann','svm','cubist']\n",
    "x_train, x2, y_train, y2 = train_test_split(x_selected, y, test_size=0.4, random_state=42)\n",
    "\n",
    "mdls = pd.DataFrame()\n",
    "mdls['model'] = models\n",
    "para = []\n",
    "score = []\n",
    "r2_tra = []\n",
    "rmse_tra = []\n",
    "r2_val = []\n",
    "rmse_val = []\n",
    "timel = []\n",
    "\n",
    "grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': [0.2, 0.5],\n",
    "    'bootstrap': True,\n",
    "    'random_state': 11,\n",
    "    'n_jobs': 40\n",
    "}\n",
    "\n",
    "grid_gbr = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'subsample': [0.6, 0.8],\n",
    "    'n_jobs': 40\n",
    "}\n",
    "\n",
    "grid_lr = {\n",
    "    'alpha': [1, 10],\n",
    "    'n_jobs': 40\n",
    "}\n",
    "\n",
    "grid_ann = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (50, 50, 25), (25, 100, 25)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'max_iter': [1000, 3000, 6000],\n",
    "    'early_stopping': True,\n",
    "    'n_jobs': 40\n",
    "}\n",
    "\n",
    "grid_svm = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0, 1, 2],\n",
    "    'gamma': [0.01, 0.1, 1, 'scale', 'auto'],\n",
    "    jobs = 40\n",
    "}\n",
    "\n",
    "grid_cubist = {\n",
    "    'committees': [5, 10, 20],\n",
    "    'neighbors': [5, 10, 20],\n",
    "    'rules': [50, 100, 200],\n",
    "    'trials': [5, 10, 20],\n",
    "    'model': ['tree', 'rules'],\n",
    "    jobs = 40\n",
    "}\n",
    "\n",
    "grids = [grid_rf, grid_gbr, grid_lr, grid_ann, grid_svm, grid_cubist]\n",
    "\n",
    "estimators = [RandomForestRegressor(),GradientBoostingRegressor(),Ridge(),\n",
    "              MLPRegressor(), SVR(), CubistRegressor()]\n",
    "\n",
    "factor = [2,2,1,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0482a60-0193-4a74-9cb1-3ad0cc822dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(x_train,y_train,name,estimator,param_grid,havling_factor):\n",
    "    sta = time.time()\n",
    "    grid = HalvingGridSearchCV(estimator, param_grid, cv=5, factor=havling_factor).fit(x_train, y_train)\n",
    "    ed = time.time()\n",
    "    \n",
    "    best = grid.best_estimator_\n",
    "\n",
    "    best.fit(x_train, y_train)\n",
    "    joblib.dump(best, f'pipeline/{name}.joblib')\n",
    "\n",
    "    y_train_pred = best.predict(x_train)\n",
    "    r2_tra.append(r2_score(y_train, y_train_pred))\n",
    "    rmse_tra.append(mean_squared_error(y_train, y_train_pred, squared=False))\n",
    "\n",
    "    y_val_pred = best.predict(x_test)\n",
    "    r2_val.append(r2_score(y_test, y_val_pred))\n",
    "    rmse_val.append(mean_squared_error(y_test, y_val_pred, squared=False))\n",
    "    \n",
    "    return [grid.best_score_,grid.best_params_,r2_tra,rmse_tra,r2_val,rmse_val,round((ed-sta)/60,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e1070-0354-4d24-9ee1-a183cfde16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    print(name[i])\n",
    "    templ = pipeline(x_train,y_train,name[i],models[i],estimators[i],grids[i],factors[i])\n",
    "    score.append(templ[0])\n",
    "    para.append(templ[1])\n",
    "    r2_tra.append(templ[2])\n",
    "    rmse_tra.append(templ[3])\n",
    "    r2_val.append(templ[4])\n",
    "    rmse_val.append(templ[5])\n",
    "    timel.append(templ[6])\n",
    "    \n",
    "mdls['model'] = models\n",
    "mdls['best_para'] = para\n",
    "mdls['score_hyper_tuning'] = score \n",
    "mdls['r2_training'] = r2_tra\n",
    "mdls['rmse_training'] = rmse_tra\n",
    "mdls['r2_validation'] = r2_val\n",
    "mdls['rmse_validation'] = rmse_val\n",
    "mdls['time'] = timel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0dcde0-e291-4633-b46f-6a37bf17d5bf",
   "metadata": {},
   "source": [
    "### build meta learner on top of base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ba336-9972-4aec-92ba-b0342a00a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_meta, x_test, y_meta, y_test = train_test_split(x2, y2, test_size=0.4, random_state=42)\n",
    "\n",
    "base_learners = {name: joblib.load(f'pipeline/{name}.joblib') for name models}\n",
    "meta_learner = LinearRegression()\n",
    "\n",
    "sta = time.time()\n",
    "meta = StackingRegressor(estimators=list(base_learners.items()), final_estimator=meta_learner, cv = 'prefit', n_jobs=40)\n",
    "meta.set_params(svm='drop')\n",
    "meta.fit(x_meta, y_meta)\n",
    "ed = time.time()\n",
    "\n",
    "joblib.dump(meta, f'pipeline/meta.joblib')\n",
    "\n",
    "y_meta_pred = meta.predict(x_meta)\n",
    "r2_tra.append(r2_score(y_meta, y_meta_pred))\n",
    "rmse_tra.append(mean_squared_error(y_meta, y_meta_pred, squared=False))\n",
    "\n",
    "y_test_pred = best.predict(x_test)\n",
    "r2_val.append(r2_score(y_test, y_test_pred))\n",
    "rmse_val.append(mean_squared_error(y_test, y_test_pred, squared=False))\n",
    "    \n",
    "mdls.loc[len(mdls)] = ['meta',meta.best_score_,metag.best_params_,r2_tra,rmse_tra,r2_val,rmse_val,round((ed-sta)/60,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf633a8-00de-4dd3-91bc-8e8f2ed96cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
